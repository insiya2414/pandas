{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688b0d55",
   "metadata": {},
   "source": [
    "### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "920f2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466aeed9",
   "metadata": {},
   "source": [
    "### Importing Dummy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b34f3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height_cm</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Department</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>Sales</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>85</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>175</td>\n",
       "      <td>78</td>\n",
       "      <td>HR</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>22</td>\n",
       "      <td>155</td>\n",
       "      <td>50</td>\n",
       "      <td>Sales</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age  Height_cm  Weight_kg   Department  Score\n",
       "0    Alice   25        165         55        Sales     88\n",
       "1      Bob   30        180         85  Engineering     92\n",
       "2  Charlie   35        175         78           HR     95\n",
       "3    Diana   40        160         60  Engineering     70\n",
       "4      Eve   22        155         50        Sales     85"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dummy_Dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98956c4",
   "metadata": {},
   "source": [
    "### Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81fb4916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of each group:\n",
      " Department\n",
      "Engineering    3\n",
      "HR             2\n",
      "Marketing      2\n",
      "Sales          3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby(\"Department\")\n",
    "\n",
    "# Size of each group\n",
    "print(\"\\nSize of each group:\\n\" , df_grouped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Score by Department\n",
      " Department\n",
      "Engineering    79.333333\n",
      "HR             87.000000\n",
      "Marketing      79.500000\n",
      "Sales          85.666667\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Mean Score by Department\n",
    "print(\"\\nMean Score by Department\\n\" , df_grouped[\"Score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cumulative some of scores within each group:\n",
      " 0     88\n",
      "1     92\n",
      "2     95\n",
      "3    162\n",
      "4    173\n",
      "5    174\n",
      "6     91\n",
      "7    159\n",
      "8    238\n",
      "9    257\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cumulative some of scores within each group - the running total for that group\n",
    "print(\"\\nCumulative some of scores within each group:\\n\", df_grouped[\"Score\"].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b42cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score ranks within department:\n",
      "       Name   Department  Score  Score_Rank\n",
      "0    Alice        Sales     88         1.0\n",
      "1      Bob  Engineering     92         1.0\n",
      "2  Charlie           HR     95         1.0\n",
      "3    Diana  Engineering     70         3.0\n",
      "4      Eve        Sales     85         2.0\n",
      "5    Frank           HR     79         2.0\n",
      "6    Grace    Marketing     91         1.0\n",
      "7     Hank    Marketing     68         2.0\n",
      "8      Ivy  Engineering     76         2.0\n",
      "9     Jack        Sales     84         3.0\n"
     ]
    }
   ],
   "source": [
    "# Rank within group\n",
    "df[\"Score_Rank\"] = df_grouped[\"Score\"].rank(ascending = False)\n",
    "print(\"\\nScore ranks within department:\\n\" , df[[\"Name\", \"Department\", \"Score\", \"Score_Rank\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807e53c",
   "metadata": {},
   "source": [
    "### Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts of department:\n",
      " Department\n",
      "Sales          3\n",
      "Engineering    3\n",
      "HR             2\n",
      "Marketing      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts of department - how many times each unique value appears in the Department column\n",
    "print(\"\\nValue counts of department:\\n\" , df[\"Department\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c135d673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Name        10 non-null     object \n",
      " 1   Age         10 non-null     int64  \n",
      " 2   Height_cm   10 non-null     int64  \n",
      " 3   Weight_kg   10 non-null     int64  \n",
      " 4   Department  10 non-null     object \n",
      " 5   Score       10 non-null     int64  \n",
      " 6   Score_Rank  10 non-null     float64\n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 692.0+ bytes\n",
      "\n",
      "Information about the dataframe:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Dataframe info\n",
    "print(\"\\nInformation about the dataframe:\\n\" , df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e339b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Stats:\n",
      "              Age  Height_cm  Weight_kg     Score  Score_Rank\n",
      "count  10.000000   10.00000  10.000000  10.00000   10.000000\n",
      "mean   30.900000  169.00000  68.800000  82.80000    1.800000\n",
      "std     5.743595    9.46338  14.366628   9.29516    0.788811\n",
      "min    22.000000  155.00000  50.000000  68.00000    1.000000\n",
      "25%    26.750000  161.25000  56.250000  76.75000    1.000000\n",
      "50%    30.500000  169.00000  69.000000  84.50000    2.000000\n",
      "75%    34.500000  176.50000  79.500000  90.25000    2.000000\n",
      "max    40.000000  182.00000  90.000000  95.00000    3.000000\n"
     ]
    }
   ],
   "source": [
    "# Statistical info about the dataset\n",
    "print(\"\\nDescriptive Stats:\\n\" , df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413de216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows & Columns:\n",
      " (10, 7)\n"
     ]
    }
   ],
   "source": [
    "# Tuple of # of rows and # of columns\n",
    "print(\"\\nNumber of Rows & Columns:\\n\" , df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264a1c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name           object\n",
      "Age             int64\n",
      "Height_cm       int64\n",
      "Weight_kg       int64\n",
      "Department     object\n",
      "Score           int64\n",
      "Score_Rank    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25    26.75\n",
       "0.75    34.50\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data type of each variable\n",
    "print(df.dtypes)\n",
    "\n",
    "# sums values of each obj\n",
    "df[\"Age\"].sum()\n",
    "\n",
    "# quantiles of each obj\n",
    "df[\"Age\"].quantile([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e6e1f",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91fec580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing some NaNs for learning\n",
    "\n",
    "df_with_nan = df.copy()\n",
    "df_with_nan.loc[2, \"Score\"] = np.nan\n",
    "df_with_nan.loc[5, \"Weight_kg\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27f529bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With Nan's:\n",
      "       Name  Age  Height_cm  Weight_kg   Department  Score  Score_Rank\n",
      "0    Alice   25        165       55.0        Sales   88.0         1.0\n",
      "1      Bob   30        180       85.0  Engineering   92.0         1.0\n",
      "2  Charlie   35        175       78.0           HR    NaN         1.0\n",
      "3    Diana   40        160       60.0  Engineering   70.0         3.0\n",
      "4      Eve   22        155       50.0        Sales   85.0         2.0\n",
      "5    Frank   29        170        NaN           HR   79.0         2.0\n",
      "6    Grace   33        168       65.0    Marketing   91.0         1.0\n",
      "7     Hank   38        182       90.0    Marketing   68.0         2.0\n",
      "8      Ivy   26        158       52.0  Engineering   76.0         2.0\n",
      "9     Jack   31        177       80.0        Sales   84.0         3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWith Nan's:\\n\" , df_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb78fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Drop Nan:\n",
      "     Name  Age  Height_cm  Weight_kg   Department  Score  Score_Rank\n",
      "0  Alice   25        165       55.0        Sales   88.0         1.0\n",
      "1    Bob   30        180       85.0  Engineering   92.0         1.0\n",
      "3  Diana   40        160       60.0  Engineering   70.0         3.0\n",
      "4    Eve   22        155       50.0        Sales   85.0         2.0\n",
      "6  Grace   33        168       65.0    Marketing   91.0         1.0\n",
      "7   Hank   38        182       90.0    Marketing   68.0         2.0\n",
      "8    Ivy   26        158       52.0  Engineering   76.0         2.0\n",
      "9   Jack   31        177       80.0        Sales   84.0         3.0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with Nan\n",
    "print(\"\\nDrop Nan:\\n\" , df_with_nan.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e76f5fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fill Nan with 0:\n",
      "       Name  Age  Height_cm  Weight_kg   Department  Score  Score_Rank\n",
      "0    Alice   25        165       55.0        Sales   88.0         1.0\n",
      "1      Bob   30        180       85.0  Engineering   92.0         1.0\n",
      "2  Charlie   35        175       78.0           HR    0.0         1.0\n",
      "3    Diana   40        160       60.0  Engineering   70.0         3.0\n",
      "4      Eve   22        155       50.0        Sales   85.0         2.0\n",
      "5    Frank   29        170        0.0           HR   79.0         2.0\n",
      "6    Grace   33        168       65.0    Marketing   91.0         1.0\n",
      "7     Hank   38        182       90.0    Marketing   68.0         2.0\n",
      "8      Ivy   26        158       52.0  Engineering   76.0         2.0\n",
      "9     Jack   31        177       80.0        Sales   84.0         3.0\n"
     ]
    }
   ],
   "source": [
    "# Fill Nan\n",
    "print(\"\\nFill Nan with 0:\\n\" , df_with_nan.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de6131",
   "metadata": {},
   "source": [
    "### Make New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfe251ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new computed column\n",
    "df = df.assign(BMI=lambda d: d[\"Weight_kg\"] / ((d[\"Height_cm\"] / 100) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "273ef6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Columns (BMI and AgeGroup):\n",
      "       Name  Age        BMI AgeGroup\n",
      "0    Alice   25  20.202020    Young\n",
      "1      Bob   30  26.234568    Young\n",
      "2  Charlie   35  25.469388  Mid-Age\n",
      "3    Diana   40  23.437500  Mid-Age\n",
      "4      Eve   22  20.811655    Young\n",
      "5    Frank   29  25.259516    Young\n",
      "6    Grace   33  23.030045  Mid-Age\n",
      "7     Hank   38  27.170632  Mid-Age\n",
      "8      Ivy   26  20.829995    Young\n",
      "9     Jack   31  25.535446  Mid-Age\n"
     ]
    }
   ],
   "source": [
    "# Categorize Age into buckets - Bin column into n buckets\n",
    "df[\"AgeGroup\"] = pd.cut(df[\"Age\"], bins=[20, 30, 40], labels=[\"Young\", \"Mid-Age\"])\n",
    "\n",
    "print(\"\\nNew Columns (BMI and AgeGroup):\\n\", df[[\"Name\", \"Age\", \"BMI\", \"AgeGroup\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099c32d",
   "metadata": {},
   "source": [
    "### Combine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06384830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset to simulate joins\n",
    "adf = pd.DataFrame({\n",
    "    \"x1\": [\"A\", \"B\", \"C\"],\n",
    "    \"x2\" : [1,2,3]\n",
    "})\n",
    "\n",
    "bdf = pd.DataFrame({\n",
    "    \"x1\": [\"B\", \"C\", \"D\"], \n",
    "    \"x3\": [\"Beta\", \"Gamma\", \"Delta\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9e57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inner Join:\n",
      "   x1  x2     x3\n",
      "0  B   2   Beta\n",
      "1  C   3  Gamma\n"
     ]
    }
   ],
   "source": [
    "# Inner join - It retains only the rows that have matching values in the 'x1' column of both DataFrames (adf and bdf)\n",
    "print(\"\\nInner Join:\\n\" , pd.merge(adf, bdf, how = \"inner\", on = \"x1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdcc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Join:\n",
      "   x1   x2     x3\n",
      "0  A  1.0    NaN\n",
      "1  B  2.0   Beta\n",
      "2  C  3.0  Gamma\n",
      "3  D  NaN  Delta\n"
     ]
    }
   ],
   "source": [
    "# Outer Join -  It keeps all rows from both DataFrames (adf and bdf)\n",
    "print(\"\\nOuter Join:\\n\", pd.merge(adf, bdf, how=\"outer\", on=\"x1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12bc7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Left Join:\n",
      "   x1  x2     x3\n",
      "0  A   1    NaN\n",
      "1  B   2   Beta\n",
      "2  C   3  Gamma\n"
     ]
    }
   ],
   "source": [
    "# Left Join - It keeps all rows from the left DataFrame (adf)\n",
    "# It attempts to find matching rows in the right DataFrame (bdf) based on the 'x1' column.\n",
    "print(\"\\nLeft Join:\\n\", pd.merge(adf, bdf, how=\"left\", on=\"x1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d103f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Right Join:\n",
      "   x1   x2     x3\n",
      "0  B  2.0   Beta\n",
      "1  C  3.0  Gamma\n",
      "2  D  NaN  Delta\n"
     ]
    }
   ],
   "source": [
    "# Right Join - It keeps all rows from the right DataFrame (bdf)\n",
    "# It attempts to find matching rows in the left DataFrame (adf) based on the 'x1' column\n",
    "print(\"\\nRight Join:\\n\", pd.merge(adf, bdf, how=\"right\", on=\"x1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e52a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering Join (Only in adf):\n",
      "   x1  x2\n",
      "1  B   2\n",
      "2  C   3\n"
     ]
    }
   ],
   "source": [
    "# Filtering Join - Keep matches only - All rows in adf that do not have a match in bdf\n",
    "print(\"\\nFiltering Join (Only in adf):\\n\", adf[adf[\"x1\"].isin(bdf[\"x1\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ce52a",
   "metadata": {},
   "source": [
    "### Set-like Merge Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c68d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame({\"merge1\": [\"A\", \"B\", \"C\"]})\n",
    "zdf = pd.DataFrame({\"merge1\": [\"B\", \"C\", \"D\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f6bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intersection:\n",
      "   merge1\n",
      "0      B\n",
      "1      C\n"
     ]
    }
   ],
   "source": [
    "# Intersection - Rows that appear in both ydf and zdf\n",
    "print(\"\\nIntersection:\\n\", pd.merge(ydf, zdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23d13da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  merge1      _merge\n",
      "0      A   left_only\n",
      "1      B        both\n",
      "2      C        both\n",
      "3      D  right_only\n"
     ]
    }
   ],
   "source": [
    "# Left Only\n",
    "left_only = pd.merge(ydf, zdf, how=\"outer\", indicator=True)\n",
    "print(left_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdf49606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Left Only:\n",
      "   merge1\n",
      "0      A\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLeft Only:\\n\", left_only.query(\"_merge == 'left_only'\").drop(columns=[\"_merge\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8417f61",
   "metadata": {},
   "source": [
    "### Rolling and Expanding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rolling Avg of Score (window=3):\n",
      "       Name  Score  Rolling_Score\n",
      "0    Alice     88            NaN\n",
      "1      Bob     92            NaN\n",
      "2  Charlie     95      91.666667\n",
      "3    Diana     70      85.666667\n",
      "4      Eve     85      83.333333\n",
      "5    Frank     79      78.000000\n",
      "6    Grace     91      85.000000\n",
      "7     Hank     68      79.333333\n",
      "8      Ivy     76      78.333333\n",
      "9     Jack     84      76.000000\n"
     ]
    }
   ],
   "source": [
    "# Simulate rolling average on Score\n",
    "\n",
    "# It creates a \"rolling window\" of size 3. For each row in the \"Score\" column, this window will \n",
    "# look at the current value and the two preceding values.\n",
    "df[\"Rolling_Score\"] = df[\"Score\"].rolling(3).mean()\n",
    "print(\"\\nRolling Avg of Score (window=3):\\n\", df[[\"Name\", \"Score\", \"Rolling_Score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanding Avg of Score:\n",
      "       Name  Score  Expanding_Score\n",
      "0    Alice     88        88.000000\n",
      "1      Bob     92        90.000000\n",
      "2  Charlie     95        91.666667\n",
      "3    Diana     70        86.250000\n",
      "4      Eve     85        86.000000\n",
      "5    Frank     79        84.833333\n",
      "6    Grace     91        85.714286\n",
      "7     Hank     68        83.500000\n",
      "8      Ivy     76        82.666667\n",
      "9     Jack     84        82.800000\n"
     ]
    }
   ],
   "source": [
    "# Expanding mean on Score\n",
    "\n",
    "# For each row in the DataFrame, the \"Expanding Score\" will contain the average of all \"Score\" values\n",
    "#  from the beginning of the DataFrame up to that row. \n",
    "df[\"Expanding_Score\"] = df[\"Score\"].expanding().mean()\n",
    "print(\"\\nExpanding Avg of Score:\\n\", df[[\"Name\", \"Score\", \"Expanding_Score\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
